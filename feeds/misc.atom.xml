<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>SoLittleCode Blog - misc</title><link href="/" rel="alternate"></link><link href="/feeds/misc.atom.xml" rel="self"></link><id>/</id><updated>2020-12-29T00:00:00+01:00</updated><entry><title>Can you calculate the probability of a bug in your code?</title><link href="/can-you-calculate-the-probability-of-a-bug-in-your-code.html" rel="alternate"></link><published>2020-12-29T00:00:00+01:00</published><updated>2020-12-29T00:00:00+01:00</updated><author><name>Tom Howlett</name></author><id>tag:None,2020-12-29:/can-you-calculate-the-probability-of-a-bug-in-your-code.html</id><summary type="html">&lt;p&gt;TLDR: Yes, here’s how&lt;/p&gt;
&lt;p&gt;Every code commit or merge is one of the critical decision points that determine whether you're helping or hindering progress. Getting it right is the difference between your customers cheering or crying over your next deploy.&lt;/p&gt;
&lt;p&gt;How do we determine whether it’s time to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;TLDR: Yes, here’s how&lt;/p&gt;
&lt;p&gt;Every code commit or merge is one of the critical decision points that determine whether you're helping or hindering progress. Getting it right is the difference between your customers cheering or crying over your next deploy.&lt;/p&gt;
&lt;p&gt;How do we determine whether it’s time to commit?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Testing&lt;/li&gt;
&lt;li&gt;Code Reviews&lt;/li&gt;
&lt;li&gt;A hunch on the unknown risk?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The hunch is crucial, years of getting it wrong helps build an intuition for the level of risk in the unknown unknowns and whether that risk is acceptable. But our otherwise sound intuition is easily derailed: tiredness, pressure, mood, frustration, recent success or failures or just plain joy at getting a tricky bit of code apparently working, all have an effect. “The emotional tail wags the rational dog.”&lt;/p&gt;
&lt;p&gt;So what if we took a more data driven approach to this crucial decision? What factors should we consider and how can we measure them?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The developer - Historically what are the odds that a developer will have a bug in their code&lt;/li&gt;
&lt;li&gt;The size of the change - The more code changed the more likely a bug has been introduced&lt;/li&gt;
&lt;li&gt;The complexity of the change - Some types of code are much more likely to contain bugs than others. We can classify types of code and factor these into our calculation. &lt;/li&gt;
&lt;li&gt;The quality of the repository - However solid your code is, if it’s sitting on shaky foundations it’s much harder to make a change without causing undesirable side effects. We can measure this by the ratio of fixes made in a commit history.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Developing a formula for this is complex, the impact of each factor will vary for each repo, and the factors influence each other. Luckily this is the kind of problem that machine learning excels at. At SoLittleCode we’ve been working on this problem for the last year and are now able to calculate probabilities of a bug in a commit with around 70% accuracy. &lt;/p&gt;
&lt;p&gt;Once you know the probability of a bug in your code what should you do about it? With a model capable of calculating the probability of a bug with any developer on the team committing that code, we can calculate whose review is most likely to find the issue. The following screenshot is what our tool adds to a PR when I try to make a change to a fork of Angular.
&lt;img alt="PR Review Image" src="/images/reviewml-screenshot.png"&gt;
I guess I’m not quite ready to start coding for Google! &lt;/p&gt;
&lt;p&gt;If you’d like to discuss other ways of using this technology please let me know.&lt;/p&gt;</content><category term="misc"></category></entry></feed>